# AI Resume Evaluation System

 An intelligent system that evaluates resume-job description compatibility using advanced AI embeddings, semantic similarity analysis, and Retrieval-Augmented Generation (RAG).

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.30+-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ðŸ“‹ Overview

The AI Resume Evaluation System leverages state-of-the-art Natural Language Processing to analyze resume-job description compatibility. By combining semantic embeddings, similarity scoring, and RAG-based AI reasoning, it provides actionable insights to help candidates optimize their applications.

### âœ¨ Key Features

- ðŸ¤– **AI-Powered Analysis** - Uses OpenRouter embeddings and LLM reasoning
- ðŸ“Š **Semantic Similarity Scoring** - Computes match percentage between resume and job requirements
- ðŸ” **RAG-Based Insights** - Retrieves relevant context and generates detailed recommendations
- ðŸ“„ **PDF Processing** - Supports text extraction with OCR fallback for scanned documents
- ðŸŽ¨ **Interactive UI** - Clean, modern Streamlit interface
- ðŸ“ˆ **Detailed Reports** - Section-wise analysis with exportable results
- âš¡ **Real-Time Processing** - Fast evaluation with progress tracking

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚  HTTP   â”‚   FastAPI Backendâ”‚  API    â”‚  OpenRouter AI  â”‚
â”‚   (Frontend)    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   (REST API)     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   (Embeddings)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                            â”‚
        â”‚                            â”‚
        â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  File Uploads   â”‚         â”‚  PDF Processing  â”‚
â”‚  User Settings  â”‚         â”‚  Text Chunking   â”‚
â”‚  Results Displayâ”‚         â”‚  Vector Storage  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  RAG Pipeline    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Backend:**
- FastAPI - High-performance API framework
- OpenRouter - AI embeddings & LLM inference
- FAISS - Vector similarity search
- pdfplumber + Tesseract OCR - Document processing

**Frontend:**
- Streamlit - Interactive web interface
- Requests - API communication

---

# ðŸ“ Project Structure

```
AI_RESUME_EVALUATION_SYSTEM/
â”‚
â”œâ”€â”€ backend/                    # FastAPI backend services
â”‚   â”œâ”€â”€ api.py                 # Main API endpoints
â”‚   â”œâ”€â”€ main.py                # Core pipeline orchestration
â”‚   â”œâ”€â”€ pdf_loader.py          # PDF text extraction
â”‚   â”œâ”€â”€ chunker.py             # Text chunking strategies
â”‚   â”œâ”€â”€ embeddings.py          # Embedding generation
â”‚   â”œâ”€â”€ similarity.py          # Similarity calculations
â”‚   â”œâ”€â”€ llm.py                 # LLM API integration
â”‚   â””â”€â”€ rag/                   # RAG components
â”‚       â”œâ”€â”€ vector_store.py    # Vector storage with FAISS
â”‚       â”œâ”€â”€ retriever.py       # Context retrieval
â”‚       â”œâ”€â”€ prompt.py          # Prompt templates
â”‚       â””â”€â”€ rag_pipeline.py    # RAG orchestration
â”‚
â”œâ”€â”€ frontend/                   # Streamlit UI
â”‚   â””â”€â”€ app.py                 # Main application interface
â”‚
â”œâ”€â”€ data/                       # Sample datasets
â”‚   â””â”€â”€ sample_input/          # Sample resume and job description
â”‚       â”œâ”€â”€ text_resume (1).pdf      # Example resume
â”‚       â””â”€â”€ job_desc.pdf             # Example job description
â”‚
â”œâ”€â”€ images/                     # Project documentation images
â”‚   â”œâ”€â”€ UI.png                 # Application user interface
â”‚   â”œâ”€â”€ evaluation.png         # Evaluation results display
â”‚   â”œâ”€â”€ result.png             # Match score results
â”‚   â””â”€â”€ retrieved_context.png  # RAG retrieved context chunks
â”‚
â”œâ”€â”€ temp_uploads/              # Temporary file storage
â”œâ”€â”€ .env                       # Environment configuration
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # Documentation
```

---

## ðŸ“¸ Screenshots

### User Interface
![UI Overview](Images/UI.png)
*Clean and intuitive Streamlit interface with sidebar settings*

### Evaluation Dashboard
![Evaluation Results](Images/evaluation.png)
*Real-time evaluation with match percentage and recommendations*

### Match Score Results
![Score Results](Images/result.png)
*Detailed results display with interpretation and actionable insights*

### RAG Retrieved Context
![Retrieved Context](Images/retrieved_context.png)
*Relevant resume and job description chunks retrieved by RAG pipeline*

---

## ðŸš€ Getting Started

### Prerequisites

- Python 3.9 or higher
- Git
- Tesseract OCR (for scanned PDFs)
- OpenRouter API key ([Get one here](https://openrouter.ai))

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/AI-Resume-Evaluation-System.git
   cd AI-Resume-Evaluation-System
   ```

2. **Create virtual environment**
   ```bash
   # Windows
   python -m venv venv
   venv\Scripts\activate

   # macOS/Linux
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install Tesseract OCR**
   
   **Windows:**
   - Download from [GitHub](https://github.com/UB-Mannheim/tesseract/wiki)
   - Install to `C:\Program Files\Tesseract-OCR`
   - Set environment variable:
     ```bash
     setx POPPLER_PATH "C:\path\to\poppler\bin"
     ```

   **macOS:**
   ```bash
   brew install tesseract poppler
   ```

   **Linux:**
   ```bash
   sudo apt-get install tesseract-ocr poppler-utils
   ```

5. **Configure environment variables**
   
   Create `.env` file in project root:
   ```env
   OPENROUTER_API_KEY=your_api_key_here
   POPPLER_PATH=C:\path\to\poppler\bin  # Windows only
   ```

---

## ðŸŽ® Running the Application

### Start Backend (Terminal 1)

```bash
cd backend
python api.py
```

**Expected output:**
```
âœ“ All imports complete
INFO: Uvicorn running on http://0.0.0.0:8000
INFO: Application startup complete
```

**API Documentation:** http://localhost:8000/docs

### Start Frontend (Terminal 2)

```bash
cd frontend
streamlit run app.py
```

**Application URL:** http://localhost:8501

---

## ðŸ’¡ How It Works

### Evaluation Pipeline

1. **Document Upload** - User uploads resume PDF and job description PDF
2. **Text Extraction** - PDFs processed with OCR fallback for scanned documents
3. **Text Chunking** - Documents split into semantic chunks (configurable size)
4. **Embedding Generation** - Each chunk converted to vector embeddings via OpenRouter
5. **Similarity Scoring** - Cosine similarity computed between resume and JD embeddings
6. **RAG Analysis** (Optional) - Relevant chunks retrieved and analyzed by LLM
7. **Report Generation** - Detailed match score, insights, and recommendations

### Scoring Interpretation

| Score Range | Match Level | Interpretation |
|------------|-------------|----------------|
| 75% - 100% | ðŸŸ¢ Excellent | Strong alignment with job requirements |
| 50% - 74%  | ðŸŸ¡ Good | Decent match with room for improvement |
| 0% - 49%   | ðŸ”´ Needs Work | Significant gaps in required qualifications |

---

## ðŸ“Š API Endpoints

### Health Check
```http
GET /health
```
**Response:** `{"status": "healthy"}`

### Evaluate Resume
```http
POST /evaluate
```

**Parameters:**
- `resume` (file) - Resume PDF
- `job_description` (file) - Job description PDF
- `chunk_size` (int, default: 500) - Words per chunk
- `use_rag` (bool, default: true) - Enable RAG evaluation

**Response:**
```json
{
  "success": true,
  "score": 0.78,
  "score_percentage": "78.00%",
  "match_level": "Excellent",
  "interpretation": {
    "message": "Your resume is an excellent match for this job!",
    "recommendations": [...]
  },
  "rag_evaluation": {
    "enabled": true,
    "llm_response": "Detailed AI analysis...",
    "retrieved_resume_chunks": [...],
    "retrieved_jd_chunks": [...]
  }
}
```

---

## ðŸ› ï¸ Configuration

### Adjustable Settings (via Streamlit UI)

- **Chunk Size** (100-1000 words) - Controls granularity of text analysis
- **RAG Evaluation** (On/Off) - Toggle LLM-powered detailed analysis

### Advanced Configuration (`.env`)

```env
# Required
OPENROUTER_API_KEY=sk-or-v1-xxxxx

# Optional (Windows)
POPPLER_PATH=C:\path\to\poppler\bin
TESSERACT_CMD=C:\Program Files\Tesseract-OCR\tesseract.exe
```

---

## ðŸ“¦ Dependencies

Core libraries installed via `requirements.txt`:

```
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
streamlit>=1.30.0
python-dotenv>=1.0.0
pdfplumber>=0.10.3
pdf2image>=1.17.0
pytesseract>=0.3.10
pillow>=10.2.0
requests>=2.31.0
numpy>=1.26.0
scikit-learn>=1.4.0
faiss-cpu>=1.7.4
```

---

## ðŸ§ª Testing

### Quick Start with Sample Files

The `data/sample_input/` folder contains example files to test the system:

```bash
# Files available:
data/sample_input/
â”œâ”€â”€ text_resume (1).pdf    # Sample candidate resume
â””â”€â”€ job_desc.pdf           # Sample job posting
```

### Test Steps

1. **Start Backend**
   ```bash
   cd backend
   python api.py
   ```

2. **Start Frontend** (New Terminal)
   ```bash
   cd frontend
   streamlit run app.py
   ```

3. **Upload Sample Files**
   - Click "Browse files" under "Resume PDF"
   - Select `data/sample_input/text_resume (1).pdf`
   - Click "Browse files" under "Job Description PDF"
   - Select `data/sample_input/job_desc.pdf`

4. **Configure Settings (Optional)**
   - Adjust "Chunk Size" slider (default: 500 words)
   - Toggle "Enable RAG Evaluation" (default: ON)

5. **Run Analysis**
   - Click "Analyze Match Score"
   - View results and AI-powered recommendations
   - Download detailed report as text file

### Test Backend Health
```bash
curl http://localhost:8000/health
```

### Test API Documentation
Navigate to: http://localhost:8000/docs

---
